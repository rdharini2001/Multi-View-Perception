# Leveraging Monocular Infrastructure Cameras for Collaborative Multi-View Perception for Indoor Autonomous Mobile Robots 
This repo contains code, data and step-by-step instructions to replicate the paper. This work can be divided into 5 phases - marker-less robot pose estimation, pose uncertainty estimation, camera placement optimziation, data association for multi-camera multi-robot navigation and sensor fusion.

# Marker-less Robot Pose Estimation
1. Download the weights file using this [link](https://drive.google.com/file/d/1scYfZa8a6hECXPae7nkQLXC1lbxKabC0/view?usp=sharing). If you wish to retrain the model, download the dataset from here: [Volta Pose](https://drive.google.com/drive/folders/1uBcb-0tSmQp2Nw9Y9dzLTH_DdySIXnbV?usp=sharing)
2. Put it in the same directory as markerless_cam_pose.py and execute the script.
3. The pose of the robot is estimated with respect to the camera's global origin.

# Pose Uncertainty Estimation




# Camera Placement Optimization
1. 

# Multi-Robot Tracking and Data Association 

# Sensor Fusion
